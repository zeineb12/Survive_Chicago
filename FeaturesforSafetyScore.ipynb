{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Features in order to Calculate Safety Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer the third research question which is \"The survival guide: a personalized guide for eating out safely\", we need to prepare a features dataframe that we are going to use to compute the safety score for each establishment*. \n",
    "\n",
    "On top of some of the given features (namely 'DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude'), we will calculate the following metrics for each establishment:\n",
    "- **Violation per Inspection :** the total number of violations over the total number of inspections\n",
    "- **Critical Violation per Inspection :** the total number of critical violations over the total number of inspections, over the total number of possible critical violations\n",
    "- **Moderate Violation per Inspection :** the total number of moderate violations over the total number of inspections, over the total number of possible moderate violations\n",
    "- **Non-Critical Violation per Inspection :** the total number of non-critical violations over the total number of inspections, over the total number of possible non-critical violations\n",
    "- **Critical Violations Ratio :** ratio of the critical violations count over total violation count\n",
    "- **Yes Ratio of Allergen :** ratio of the 'Allergen Yes Counts' over the total number of inspections ('Allergen Yes Count' being the total number of inspectior comments which included allergen complaints)\n",
    "- **Yes Ratio of VomitDiarrheal :** ratio of the 'VomitDiarrheal Yes Counts' over the total number of inspections ('VomitDiarrheal Yes Counts' being the total number of inspectior comments which included poisoning complaints)\n",
    "- **Yelp Rating :** normalized user rating given for establishment on Yelp.com\n",
    "\n",
    "*Note that each establishment has a unique DBA Name and a unique address (i.e. we do not consider each DBA Name but rather each tuple made out of DBA Name and address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load Main Dataset: Chicago Food Inspection (CFI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. A bit of cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the cleaned dataset\n",
    "cfi_dataset = pd.read_pickle('datasets/cleaned_inspections.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the restaurants dataset by filtering it in 'Facility Type' column\n",
    "cfi_selected = cfi_dataset[cfi_dataset['Facility Type'].isin(['Bakery', 'Coffeeshop', 'Drinks Establishment', \n",
    "                                                              'Vending', 'Dessert Establishment', 'Restaurant'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevent columns\n",
    "cfi_selected = cfi_selected[['Inspection ID', 'DBA Name', 'License #', 'Address', 'Facility Type', 'Inspection Date', \n",
    "                             'Results', 'Latitude', 'Longitude', 'Community Area', 'Violation Numbers', \n",
    "                             'Violation Comments']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw the following in Milestone 2 <img src=\"images/countresult.png\" style=\"height:200px\"> \n",
    "\n",
    "Hence, we only keep the data with \"Pass\", \"Fail\", \"Pass w/ Conditions\" results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the wanted results from data \n",
    "cfi_selected = cfi_selected[cfi_selected['Results'].isin(['Pass', \"Fail\", \"Pass w/ Conditions\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 'DataCleaningAndExploratoryAnalysis.ipynb', we saw that the number of inspections increased over the years. However, in November 2019, we see a big drop. <img src=\"images/linegraph.png\" style=\"height:400px\"> \n",
    "We downloaded the dataset at the start of November 2019. Hence, this drop was expected. But in order to avoid any misinterpretations later in the safety score calculation, we will remove all data with inspection date after October 2019 (included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inspection Year</th>\n",
       "      <th>Inspection Month</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Inspection Year  Inspection Month  Count\n",
       "0               2010                 1    803\n",
       "1               2010                 2    828\n",
       "2               2010                 3    844\n",
       "3               2010                 4    800\n",
       "4               2010                 5    786\n",
       "..               ...               ...    ...\n",
       "114             2019                 7    883\n",
       "115             2019                 8    951\n",
       "116             2019                 9    702\n",
       "117             2019                10    760\n",
       "118             2019                11     77\n",
       "\n",
       "[119 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfi_selected['Inspection Year'] = [x.year for x in cfi_selected['Inspection Date']]\n",
    "cfi_selected['Inspection Month'] = [x.month for x in cfi_selected['Inspection Date']]\n",
    "group_by_inspection_date = cfi_selected.groupby(by=['Inspection Year', 'Inspection Month']).size().reset_index(name=\"Count\")\n",
    "group_by_inspection_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the size of the data before dropping the 2019.11's data.\n",
    "before_length = len(cfi_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We successfully removed 77 of the inpections data which come from the date of 2019.11.\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe where inspection date year is 2019 and inspection date month is 11\n",
    "cfi_201911 = cfi_selected[(cfi_selected['Inspection Year'] == 2019) & (cfi_selected['Inspection Month'] == 11)]\n",
    "combined = cfi_selected.append(cfi_201911)\n",
    "cfi_selected = combined[~combined.index.duplicated(keep=False)].reset_index()\n",
    "\n",
    "# Calculate the size of the data after dropping the 2019.11's data.\n",
    "after_length = len(cfi_selected)\n",
    "print('We successfully removed {} of the inpections data which come from the date of 2019.11.'.format(before_length-after_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop unnecessary columns\n",
    "cfi_selected = cfi_selected.drop(['index', 'Inspection Date', 'Inspection Year', 'Inspection Month'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Creating violation features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the different ratios that we require for score computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into two so as to be able to calculate violation counts over the list of violation numbers\n",
    "\n",
    "# The dataset where the Violation Numbers column is NaN\n",
    "cfi_selected_nan = cfi_selected[pd.isnull(cfi_selected['Violation Numbers'])]\n",
    "cfi_selected_nan = cfi_selected_nan.reset_index().drop(columns = 'index')\n",
    "\n",
    "# The dataset where the Violation Numbers column is not NaN\n",
    "cfi_selected_filled = cfi_selected[~pd.isnull(cfi_selected['Violation Numbers'])]\n",
    "cfi_selected_filled = cfi_selected_filled.reset_index().drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataframe is 116709 before splitting.\n",
      "The length of the dataframe is 116709 after splitting.\n"
     ]
    }
   ],
   "source": [
    "print('The length of the dataframe is {} before splitting.'.format(len(cfi_selected)))\n",
    "print('The length of the dataframe is {} after splitting.'.format(len(cfi_selected_nan)+len(cfi_selected_filled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a new column for the total number of violation counts\n",
    "cfi_selected_filled['Violation Counts'] = [len(cfi_selected_filled['Violation Numbers'][i]) for i in range(len(cfi_selected_filled))]\n",
    "\n",
    "# For NaN values this count is set to 0 since there is no violations reported by the inspectors for those\n",
    "cfi_selected_nan['Violation Counts'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of violation counts according to range of gradings based on the given source below\n",
    "# source: https://data.cityofchicago.org/api/assets/BAD5301B-681A-4202-9D25-51B2CAE672FF\n",
    "'''\n",
    "Count the violation numbers for each inspection:\n",
    "Since we have  45 distinct violations (violation numbers 1-44 and 70). \n",
    "We used the explanation given in the source: An inspection can pass, pass with conditions or fail. Establishments receiving a ‘pass’ were found to \n",
    "have no critical or serious violations (violation number 1-14 and 15-29, respectively).\n",
    "\n",
    "Hence, we decided to use following mapping:\n",
    "if there is violation number between 1 and 14 points it will be counted as 'Critical Violations Count'\n",
    "if there is violation number between 15 and 29 points it will be counted as 'Moderate Violations Count'\n",
    "if there is violation number between 30 and more points it will be counted as 'Non-Critical Violations Count'\n",
    "'''\n",
    "\n",
    "cfi_selected_filled['Critical Violations Count'] = [int(len([ i for i in cfi_selected_filled['Violation Numbers'][k] if i<=14])) for k in range(len(cfi_selected_filled))]\n",
    "cfi_selected_filled['Moderate Violations Count'] = [int(len([ i for i in cfi_selected_filled['Violation Numbers'][k] if i>=15 and i<=29])) for k in range(len(cfi_selected_filled))]\n",
    "cfi_selected_filled['Non-Critical Violations Count'] = [int(len([ i for i in cfi_selected_filled['Violation Numbers'][k] if i>=30])) for k in range(len(cfi_selected_filled))]\n",
    "\n",
    "# For NaN values these counts are set to 0 since there is no violations reported by the inspectors for those\n",
    "cfi_selected_nan['Critical Violations Count'] = 0\n",
    "cfi_selected_nan['Moderate Violations Count'] = 0\n",
    "cfi_selected_nan['Non-Critical Violations Count'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the \"Violation Comments\" column, namely to extract whether there were poisoning complaints from the inspector. We use this to create a food poisoning flag, and compute the ratio of outcomes with such complaints over all inspections for each establishment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding Allergen flag to the dataset\n",
    "cfi_selected_filled['Allergen Flag'] = np.nan\n",
    "all_comments = []\n",
    "for i in range(len(cfi_selected_filled)):\n",
    "    comment = pd.Series([x.strip() for x in cfi_selected_filled['Violation Comments'][i]])\n",
    "    all_comments.append(comment) # List of series objects\n",
    "\n",
    "cfi_selected_filled['temp'] = [(all_comments[i].astype(str).str.contains('ALLERGEN', flags=re.IGNORECASE, regex=True)== True).any() for i in range(len(all_comments))]\n",
    "cfi_selected_filled['Allergen Flag'] = ['Y' if str(x) == 'True' else 'N' for x in cfi_selected_filled['temp']]\n",
    "      \n",
    "# For NaN values dataset this flag is set to 'N' since there is no violation comments for those, we can safely say that there is no issue with them\n",
    "cfi_selected_nan['Allergen Flag'] = 'N'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Vomit or Diarrheal Events Flag to the dataset\n",
    "cfi_selected_filled['Vomit or Diarrheal Flag'] = np.nan\n",
    "all_comments = []\n",
    "for i in range(len(cfi_selected_filled)):\n",
    "    comment = pd.Series([x.strip() for x in cfi_selected_filled['Violation Comments'][i]])\n",
    "    all_comments.append(comment) # List of series objects\n",
    "    \n",
    "cfi_selected_filled['temp_vomit'] = [(all_comments[i].astype(str).str.contains('VOMIT', flags=re.IGNORECASE, regex=True)== True).any() for i in range(len(all_comments))]\n",
    "cfi_selected_filled['temp_diarrheal'] = [(all_comments[i].astype(str).str.contains('DIARRHEAL', flags=re.IGNORECASE, regex=True)== True).any() for i in range(len(all_comments))]\n",
    "cfi_selected_filled['temp1'] = (cfi_selected_filled['temp_vomit'] | cfi_selected_filled['temp_diarrheal'])\n",
    "cfi_selected_filled['Vomit or Diarrheal Flag'] = ['Y' if str(x) == 'True' else 'N' for x in cfi_selected_filled['temp1']]\n",
    "      \n",
    "# For NaN values dataset this flag is set to 'N' since there is no violation comments for those, we can safely say that there is no issue with them\n",
    "cfi_selected_nan['Vomit or Diarrheal Flag'] = 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "cfi_selected_filled = cfi_selected_filled.drop(['temp', 'temp_vomit', 'temp_diarrheal', 'temp1'], axis=1).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataframe is 116709 before merging.\n"
     ]
    }
   ],
   "source": [
    "print('The length of the dataframe is {} before merging.'.format(len(cfi_selected)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge two dataframes that we divided into two above\n",
    "cfi_selected = pd.concat([cfi_selected_filled, cfi_selected_nan])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the dataframe is 116709 after merging.\n"
     ]
    }
   ],
   "source": [
    "print('The length of the dataframe is {} after merging.'.format(len(cfi_selected)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now safely drop the 'Violation Comments' and the 'Violation Numbers' columns as we have extracted the features we need from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_selected = cfi_selected.drop(['Violation Comments', 'Violation Numbers'] ,axis=1).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn our attention to inspection outcomes.\n",
    "\n",
    "In order to calculate the rate of the failed ('Fail' results) inspections and successful (here we consider successful as combination of 'Pass' and 'Pass w/ Conditions') inspections we do following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_results = cfi_selected[['Inspection ID', 'DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude', 'Results']]\\\n",
    "                                    .groupby(by=['DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude', 'Results'])\\\n",
    "                                    .size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the 'Pass w/ Conditions' to 'Pass' and keeping all other results as it is\n",
    "grouped_by_results['Results'] = grouped_by_results['Results'].map({'Pass w/ Conditions': 'Pass', \n",
    "                                                                  'Pass': 'Pass',\n",
    "                                                                  'Fail': 'Fail'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique establishments' names, licence number, community areas, latitude and longitude\n",
    "grouped_dba_names_area = grouped_by_results[['DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude']]\\\n",
    "                                        .drop_duplicates().reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_results(df):\n",
    "    '''\n",
    "    Function to get sum over all 'Pass' results and 'Fail' results separately into two variables\n",
    "    Arguments:\n",
    "    df - dataframe to consider\n",
    "    Returns:\n",
    "    List l such that:\n",
    "        l[0] contains the number of passes\n",
    "        l[1] contains the number of fails\n",
    "    '''\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis=1)\n",
    "    succes_sum = sum(df[(df['Results'] == 'Pass')]['Count'])\n",
    "    fail_sum = sum(df[(df['Results'] == 'Fail')]['Count'])\n",
    "    return [succes_sum, fail_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new column named 'Successful Inspection Count' for total number of the pass counts\n",
    "grouped_dba_names_area['Successful Inspection Count'] = [get_sum_results(grouped_by_results[(grouped_by_results['DBA Name']==grouped_dba_names_area['DBA Name'][i]) & (grouped_by_results['Community Area']==grouped_dba_names_area['Community Area'][i])])[0] for i in range(len(grouped_dba_names_area))]\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'Failed Inspection Count' for total number of the fail counts\n",
    "grouped_dba_names_area['Failed Inspection Count'] = [get_sum_results(grouped_by_results[(grouped_by_results['DBA Name']==grouped_dba_names_area['DBA Name'][i]) & (grouped_by_results['Community Area']==grouped_dba_names_area['Community Area'][i])])[-1] for i in range(len(grouped_dba_names_area))]\n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to aggregate the 'Vomit or Diarrheal Flag' feature we follow similar steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_vomitDiarrheal = cfi_selected[['Inspection ID', 'DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude', \n",
    "                                             'Vomit or Diarrheal Flag']]\\\n",
    "                                        .groupby(by=['DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude', \n",
    "                                                     'Vomit or Diarrheal Flag'])\\\n",
    "                                        .size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_VomitDiarrheal(df):\n",
    "    '''\n",
    "    Function to get sum over all 'Yes' and 'No' Vomit or Diarrheal Flag separately into two variables\n",
    "    Arguments:\n",
    "    df - dataframe to consider\n",
    "    Returns:\n",
    "    List l such that:\n",
    "        l[0] contains the number of poisoning complaints\n",
    "        l[1] contains the number of inspection outcomes with no poisoning complaints\n",
    "    '''\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis=1)\n",
    "    yes_count = sum(df[(df['Vomit or Diarrheal Flag'] == 'Y')]['Count'])\n",
    "    no_count = sum(df[(df['Vomit or Diarrheal Flag'] == 'N')]['Count'])\n",
    "    return [yes_count, no_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'VomitDiarrheal Yes Counts' for total number of the yes counts\n",
    "grouped_dba_names_area['VomitDiarrheal Yes Counts'] = [get_count_VomitDiarrheal(grouped_by_vomitDiarrheal[(grouped_by_vomitDiarrheal['DBA Name']==grouped_dba_names_area['DBA Name'][i]) & (grouped_by_vomitDiarrheal['Community Area']==grouped_dba_names_area['Community Area'][i])])[0] for i in range(len(grouped_dba_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'VomitDiarrheal No Counts' for total number of the no counts\n",
    "grouped_dba_names_area['VomitDiarrheal No Counts'] = [get_count_VomitDiarrheal(grouped_by_vomitDiarrheal[(grouped_by_vomitDiarrheal['DBA Name']==grouped_dba_names_area['DBA Name'][i]) & (grouped_by_vomitDiarrheal['Community Area']==grouped_dba_names_area['Community Area'][i])])[-1] for i in range(len(grouped_dba_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to aggregate the 'Allergen Flag' feature we follow similar steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_allergen = cfi_selected[['Inspection ID', 'DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude', 'Allergen Flag']]\\\n",
    "                                    .groupby(by=['DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude', 'Allergen Flag'])\\\n",
    "                                    .size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_allergen(df):\n",
    "    '''\n",
    "    Function to get sum over all 'Yes' and 'No' allergen Flag separately into two variables\n",
    "    Arguments:\n",
    "    df - dataframe to consider\n",
    "    Returns:\n",
    "    List l such that:\n",
    "        l[0] contains the number of allergen complaints\n",
    "        l[1] contains the number of inspection outcomes with no allergen complaints\n",
    "    '''\n",
    "    df = df.reset_index()\n",
    "    df = df.drop('index', axis=1)\n",
    "    yes_count = sum(df[(df['Allergen Flag'] == 'Y')]['Count'])\n",
    "    no_count = sum(df[(df['Allergen Flag'] == 'N')]['Count'])\n",
    "    return [yes_count, no_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'Allergen Yes Counts' for total number of the yes counts\n",
    "grouped_dba_names_area['Allergen Yes Counts'] = [get_count_allergen(grouped_by_allergen[(grouped_by_allergen['DBA Name']==grouped_dba_names_area['DBA Name'][i]) & (grouped_by_allergen['Community Area']==grouped_dba_names_area['Community Area'][i])])[0] for i in range(len(grouped_dba_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column named 'N VomitDiarrheal Counts' for total number of the no counts\n",
    "grouped_dba_names_area['Allergen No Counts'] = [get_count_allergen(grouped_by_allergen[(grouped_by_allergen['DBA Name']==grouped_dba_names_area['DBA Name'][i]) & (grouped_by_allergen['Community Area']==grouped_dba_names_area['Community Area'][i])])[-1] for i in range(len(grouped_dba_names_area))]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now aggregate the violation count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_violations_sum = cfi_selected.groupby(by=['DBA Name', 'Address', 'Community Area', 'Facility Type', 'Latitude', 'Longitude'])\\\n",
    "                                                .agg({'Violation Counts': 'sum',\n",
    "                                                      'Critical Violations Count': 'sum',\n",
    "                                                      'Moderate Violations Count': 'sum',\n",
    "                                                      'Non-Critical Violations Count': 'sum',\n",
    "                                                      }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two datasets that we aggregated above: grouped_violations_sum and grouped_dba_names_area\n",
    "features_dataframe = grouped_violations_sum.merge(grouped_dba_names_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization:\n",
    "# Add columns for total counts and rate of counts and flags to use in further analysis in the score calculation\n",
    "features_dataframe['Total Inspections Result Counts']  = (features_dataframe['Successful Inspection Count'] + features_dataframe['Failed Inspection Count'])\n",
    "features_dataframe['Total VomitDiarrheal Flag Counts'] = (features_dataframe['VomitDiarrheal Yes Counts'] + features_dataframe['VomitDiarrheal No Counts'])\n",
    "features_dataframe['Total Allergen Flag Counts']       = (features_dataframe['Allergen Yes Counts'] + features_dataframe['Allergen No Counts'])\n",
    "\n",
    "features_dataframe['Violation per Inspection']              = (features_dataframe['Violation Counts'] / (features_dataframe['Total Inspections Result Counts']*45)) # 45 is the total possible violation numbers that one establishment can have\n",
    "features_dataframe['Critical Violation per Inspection']     = (features_dataframe['Critical Violations Count'] / (features_dataframe['Total Inspections Result Counts']*14)) # 14 is the total possible critical violation numbers that one establishment can have\n",
    "features_dataframe['Moderate Violation per Inspection']     = (features_dataframe['Moderate Violations Count'] / (features_dataframe['Total Inspections Result Counts']*15)) # 15 is the total possible moderate violation numbers that one establishment can have\n",
    "features_dataframe['Non-Critical Violation per Inspection'] = (features_dataframe['Non-Critical Violations Count'] / (features_dataframe['Total Inspections Result Counts']*16)) # 16 is the total possible non-critical violation numbers that one establishment can have\n",
    "\n",
    "features_dataframe['Success Ratio of Inspections'] = (features_dataframe['Successful Inspection Count'] / features_dataframe['Total Inspections Result Counts'])\n",
    "features_dataframe['Failure Ratio of Inspections'] = (features_dataframe['Failed Inspection Count'] / features_dataframe['Total Inspections Result Counts'])\n",
    "features_dataframe['Yes Ratio of VomitDiarrheal']  = (features_dataframe['VomitDiarrheal Yes Counts'] / features_dataframe['Total VomitDiarrheal Flag Counts'])\n",
    "features_dataframe['No Ratio of VomitDiarrheal']   = (features_dataframe['VomitDiarrheal No Counts'] / features_dataframe['Total VomitDiarrheal Flag Counts'])\n",
    "features_dataframe['Yes Ratio of Allergen']        = (features_dataframe['Allergen Yes Counts'] / features_dataframe['Total Allergen Flag Counts'])\n",
    "features_dataframe['No Ratio of Allergen']         = (features_dataframe['Allergen No Counts'] / features_dataframe['Total Allergen Flag Counts'])\n",
    "\n",
    "features_dataframe['Critical Violations Ratio']     = (features_dataframe['Critical Violations Count'] / features_dataframe['Violation Counts'])\n",
    "features_dataframe['Moderate Violations Ratio']     = (features_dataframe['Moderate Violations Count'] / features_dataframe['Violation Counts'])\n",
    "features_dataframe['Non-Critical Violations Ratio'] = (features_dataframe['Non-Critical Violations Count'] / features_dataframe['Violation Counts'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBA Name                                    0\n",
       "Address                                     0\n",
       "Community Area                              0\n",
       "Facility Type                               0\n",
       "Latitude                                    0\n",
       "Longitude                                   0\n",
       "Violation Counts                            0\n",
       "Critical Violations Count                   0\n",
       "Moderate Violations Count                   0\n",
       "Non-Critical Violations Count               0\n",
       "Successful Inspection Count                 0\n",
       "Failed Inspection Count                     0\n",
       "VomitDiarrheal Yes Counts                   0\n",
       "VomitDiarrheal No Counts                    0\n",
       "Allergen Yes Counts                         0\n",
       "Allergen No Counts                          0\n",
       "Total Inspections Result Counts             0\n",
       "Total VomitDiarrheal Flag Counts            0\n",
       "Total Allergen Flag Counts                  0\n",
       "Violation per Inspection                    0\n",
       "Critical Violation per Inspection           0\n",
       "Moderate Violation per Inspection           0\n",
       "Non-Critical Violation per Inspection       0\n",
       "Success Ratio of Inspections                0\n",
       "Failure Ratio of Inspections                0\n",
       "Yes Ratio of VomitDiarrheal                 0\n",
       "No Ratio of VomitDiarrheal                  0\n",
       "Yes Ratio of Allergen                       0\n",
       "No Ratio of Allergen                        0\n",
       "Critical Violations Ratio                1531\n",
       "Moderate Violations Ratio                1531\n",
       "Non-Critical Violations Ratio            1531\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether there are NaN values in the dataset\n",
    "features_dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some establishment did not have violations in any of their inspections. Hence, they get NaN's for the \"Critical Violations Ratio\", \"Moderate Violations Ratio\", and \"Non-Critical Violations Ratio\" columns. Hence, we can safely replace these values with $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fillna values with 0; cause this NaN is resulted from violations count column which is 0 for each of them\n",
    "features_dataframe['Critical Violations Ratio'].fillna(0, inplace=True)    \n",
    "features_dataframe['Moderate Violations Ratio'].fillna(0, inplace=True)    \n",
    "features_dataframe['Non-Critical Violations Ratio'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Violation Counts</th>\n",
       "      <th>Critical Violations Count</th>\n",
       "      <th>Moderate Violations Count</th>\n",
       "      <th>Non-Critical Violations Count</th>\n",
       "      <th>Successful Inspection Count</th>\n",
       "      <th>Failed Inspection Count</th>\n",
       "      <th>VomitDiarrheal Yes Counts</th>\n",
       "      <th>VomitDiarrheal No Counts</th>\n",
       "      <th>...</th>\n",
       "      <th>Non-Critical Violation per Inspection</th>\n",
       "      <th>Success Ratio of Inspections</th>\n",
       "      <th>Failure Ratio of Inspections</th>\n",
       "      <th>Yes Ratio of VomitDiarrheal</th>\n",
       "      <th>No Ratio of VomitDiarrheal</th>\n",
       "      <th>Yes Ratio of Allergen</th>\n",
       "      <th>No Ratio of Allergen</th>\n",
       "      <th>Critical Violations Ratio</th>\n",
       "      <th>Moderate Violations Ratio</th>\n",
       "      <th>Non-Critical Violations Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "      <td>16788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.888070</td>\n",
       "      <td>-87.674171</td>\n",
       "      <td>22.475399</td>\n",
       "      <td>2.209971</td>\n",
       "      <td>2.142781</td>\n",
       "      <td>18.122647</td>\n",
       "      <td>7.516679</td>\n",
       "      <td>1.850608</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>8.911127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148044</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.208627</td>\n",
       "      <td>0.046603</td>\n",
       "      <td>0.953397</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>0.968837</td>\n",
       "      <td>0.084222</td>\n",
       "      <td>0.085868</td>\n",
       "      <td>0.738714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074302</td>\n",
       "      <td>0.054322</td>\n",
       "      <td>22.926222</td>\n",
       "      <td>3.084065</td>\n",
       "      <td>2.704448</td>\n",
       "      <td>18.615376</td>\n",
       "      <td>14.586904</td>\n",
       "      <td>2.755795</td>\n",
       "      <td>1.028594</td>\n",
       "      <td>16.215964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102496</td>\n",
       "      <td>0.203210</td>\n",
       "      <td>0.203210</td>\n",
       "      <td>0.119564</td>\n",
       "      <td>0.119564</td>\n",
       "      <td>0.097582</td>\n",
       "      <td>0.097582</td>\n",
       "      <td>0.115824</td>\n",
       "      <td>0.104550</td>\n",
       "      <td>0.278550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.644670</td>\n",
       "      <td>-87.914428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.853993</td>\n",
       "      <td>-87.703192</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.895615</td>\n",
       "      <td>-87.663963</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054201</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.939721</td>\n",
       "      <td>-87.634848</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.020808</td>\n",
       "      <td>-87.526940</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Latitude     Longitude  Violation Counts  \\\n",
       "count  16788.000000  16788.000000      16788.000000   \n",
       "mean      41.888070    -87.674171         22.475399   \n",
       "std        0.074302      0.054322         22.926222   \n",
       "min       41.644670    -87.914428          0.000000   \n",
       "25%       41.853993    -87.703192          6.000000   \n",
       "50%       41.895615    -87.663963         15.000000   \n",
       "75%       41.939721    -87.634848         33.000000   \n",
       "max       42.020808    -87.526940        393.000000   \n",
       "\n",
       "       Critical Violations Count  Moderate Violations Count  \\\n",
       "count               16788.000000               16788.000000   \n",
       "mean                    2.209971                   2.142781   \n",
       "std                     3.084065                   2.704448   \n",
       "min                     0.000000                   0.000000   \n",
       "25%                     0.000000                   0.000000   \n",
       "50%                     1.000000                   1.000000   \n",
       "75%                     3.000000                   3.000000   \n",
       "max                    42.000000                  35.000000   \n",
       "\n",
       "       Non-Critical Violations Count  Successful Inspection Count  \\\n",
       "count                   16788.000000                 16788.000000   \n",
       "mean                       18.122647                     7.516679   \n",
       "std                        18.615376                    14.586904   \n",
       "min                         0.000000                     0.000000   \n",
       "25%                         5.000000                     2.000000   \n",
       "50%                        12.000000                     4.000000   \n",
       "75%                        26.000000                     9.000000   \n",
       "max                       321.000000                   220.000000   \n",
       "\n",
       "       Failed Inspection Count  VomitDiarrheal Yes Counts  \\\n",
       "count             16788.000000               16788.000000   \n",
       "mean                  1.850608                   0.456159   \n",
       "std                   2.755795                   1.028594   \n",
       "min                   0.000000                   0.000000   \n",
       "25%                   0.000000                   0.000000   \n",
       "50%                   1.000000                   0.000000   \n",
       "75%                   2.000000                   1.000000   \n",
       "max                  35.000000                  12.000000   \n",
       "\n",
       "       VomitDiarrheal No Counts  ...  Non-Critical Violation per Inspection  \\\n",
       "count              16788.000000  ...                           16788.000000   \n",
       "mean                   8.911127  ...                               0.148044   \n",
       "std                   16.215964  ...                               0.102496   \n",
       "min                    0.000000  ...                               0.000000   \n",
       "25%                    2.000000  ...                               0.076389   \n",
       "50%                    5.000000  ...                               0.140625   \n",
       "75%                   11.000000  ...                               0.206250   \n",
       "max                  248.000000  ...                               1.000000   \n",
       "\n",
       "       Success Ratio of Inspections  Failure Ratio of Inspections  \\\n",
       "count                  16788.000000                  16788.000000   \n",
       "mean                       0.791373                      0.208627   \n",
       "std                        0.203210                      0.203210   \n",
       "min                        0.000000                      0.000000   \n",
       "25%                        0.666667                      0.000000   \n",
       "50%                        0.818182                      0.181818   \n",
       "75%                        1.000000                      0.333333   \n",
       "max                        1.000000                      1.000000   \n",
       "\n",
       "       Yes Ratio of VomitDiarrheal  No Ratio of VomitDiarrheal  \\\n",
       "count                 16788.000000                16788.000000   \n",
       "mean                      0.046603                    0.953397   \n",
       "std                       0.119564                    0.119564   \n",
       "min                       0.000000                    0.000000   \n",
       "25%                       0.000000                    0.963964   \n",
       "50%                       0.000000                    1.000000   \n",
       "75%                       0.036036                    1.000000   \n",
       "max                       1.000000                    1.000000   \n",
       "\n",
       "       Yes Ratio of Allergen  No Ratio of Allergen  Critical Violations Ratio  \\\n",
       "count           16788.000000          16788.000000               16788.000000   \n",
       "mean                0.031163              0.968837                   0.084222   \n",
       "std                 0.097582              0.097582                   0.115824   \n",
       "min                 0.000000              0.000000                   0.000000   \n",
       "25%                 0.000000              1.000000                   0.000000   \n",
       "50%                 0.000000              1.000000                   0.054201   \n",
       "75%                 0.000000              1.000000                   0.130435   \n",
       "max                 1.000000              1.000000                   1.000000   \n",
       "\n",
       "       Moderate Violations Ratio  Non-Critical Violations Ratio  \n",
       "count               16788.000000                   16788.000000  \n",
       "mean                    0.085868                       0.738714  \n",
       "std                     0.104550                       0.278550  \n",
       "min                     0.000000                       0.000000  \n",
       "25%                     0.000000                       0.694444  \n",
       "50%                     0.066667                       0.812500  \n",
       "75%                     0.128205                       0.909091  \n",
       "max                     1.000000                       1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pickle\n",
    "features_dataframe.to_pickle('pickles/features_dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Secondary Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have the information about if the given facility is in a chain or not. In order to find that, we use a secondary dataset to get the chain establishment names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fast food restaurants dataset and saved features from the Part I\n",
    "fast_foods = pd.read_csv('datasets/FastFoodRestaurants.csv')\n",
    "features_dataframe = pd.read_pickle('pickles/features_dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only keep the restaurants that appear more than once\n",
    "chain_counts = (fast_foods['name'].value_counts())\n",
    "fast_food_chains = chain_counts[chain_counts.values>1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 173 chains in the secondary dataset which is called \"FastFoodRestaurants.csv\".\n"
     ]
    }
   ],
   "source": [
    "print('There are {} chains in the secondary dataset which is called \"FastFoodRestaurants.csv\".'.format(len(fast_food_chains)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 173 chain names do not cover all chain establishments in our dataset. Hence, we chose to set a chain flag and set it to 'Y' every time an establishments appears more than twice in our dataset. We do this by checking if an establishment has more than one address (using the latitude and longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_chains = features_dataframe[['DBA Name', 'Address', 'Latitude', 'Longitude']].drop_duplicates().reset_index().drop('index', axis=1)\n",
    "grouped_by_dbaname = additional_chains.groupby(by=['DBA Name']).size().reset_index(name=\"Count\")\n",
    "establishments_repeted = grouped_by_dbaname[grouped_by_dbaname['Count']>1].reset_index()\n",
    "other_fast_food_chains = set(establishments_repeted['DBA Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 972 establishments which have more than one location can be seen as chains.\n"
     ]
    }
   ],
   "source": [
    "print('There are {} establishments which have more than one location can be seen as chains.'.format(len(other_fast_food_chains)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add those unique establishment names to our secondary chains dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the set of chain establishments in the dataset\n",
    "fast_food_chains.extend(other_fast_food_chains)\n",
    "fast_food_chains = set(fast_food_chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After extending the set of chains, we have 1136 food chains in total.\n"
     ]
    }
   ],
   "source": [
    "print('After extending the set of chains, we have {} food chains in total.'.format(len(fast_food_chains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the char '\\'' for simplicity, transform everything to lowercase and remove duplicates\n",
    "fast_food_chains = set([chain_name.replace(\"\\'\", \"\").lower() for chain_name in fast_food_chains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalizing the set of chains, we have 1048 unique food chains names in total.\n"
     ]
    }
   ],
   "source": [
    "print('After normalizing the set of chains, we have {} unique food chains names in total.'.format(len(fast_food_chains)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add the flag to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new column \"Chain flag\" for food chains\n",
    "# We fill the column with 'N' for No' and 'Y' for 'Yes' if the establishment name exists (or not exist) in the fast_food_chains\n",
    "boolean_foodchains = pd.DataFrame(features_dataframe['DBA Name'].str.replace(\"\\'\", \"\")\\\n",
    "                                  .str.lower().isin(fast_food_chains)).rename(columns={\"DBA Name\": \"Chain flag temp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the boolean_foodchains['Chain flag temp'] columns to the main dataset CFI as a new column: 'Chain flag'\n",
    "features_dataframe['Chain flag'] = boolean_foodchains['Chain flag temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to use the Yelp dataset to see whether the rating information (for the establishments) given by Yelp users can be used in the safety score calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read yelp dataset\n",
    "yelp_dataset = pd.read_pickle('pickles/business_details.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fetch out the establishment ratings given by Yelp users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lowercased Name</th>\n",
       "      <th>Lowercased Address</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carniceria y fruteria los altos</td>\n",
       "      <td>2959 w 40th st</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>al's beef</td>\n",
       "      <td>234 s wabash ave</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peking mandarin</td>\n",
       "      <td>3459 w lawrence ave</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la humita</td>\n",
       "      <td>3466 n pulaski rd</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicago produce</td>\n",
       "      <td>3500 w lawrence ave</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Lowercased Name   Lowercased Address  rating\n",
       "0  carniceria y fruteria los altos       2959 w 40th st     3.5\n",
       "1                        al's beef     234 s wabash ave     3.0\n",
       "2                  peking mandarin  3459 w lawrence ave     4.0\n",
       "3                        la humita    3466 n pulaski rd     4.0\n",
       "4                  chicago produce  3500 w lawrence ave     3.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the fetaures that we need\n",
    "yelp_dataset = yelp_dataset[['name', 'location.address1', 'rating']]\n",
    "yelp_dataset['Lowercased Address'] = yelp_dataset['location.address1'].str.lower()\n",
    "yelp_dataset['Lowercased Name'] = yelp_dataset['name'].str.lower()\n",
    "yelp_dataset = yelp_dataset.drop(['location.address1', 'name'], axis=1)\n",
    "yelp_dataset = yelp_dataset.drop_duplicates()\n",
    "yelp_dataset = yelp_dataset[['Lowercased Name', 'Lowercased Address', 'rating']]\n",
    "yelp_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lowercased Name       1\n",
       "Lowercased Address    1\n",
       "rating                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there NaN values in the dataset\n",
    "yelp_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the rows where all the columns coming from the Yelp dataset are NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_dataset = yelp_dataset.dropna(how='all').reset_index().drop(['index'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.537314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.905850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  14284.000000\n",
       "mean       3.537314\n",
       "std        0.905850\n",
       "min        1.000000\n",
       "25%        3.000000\n",
       "50%        3.500000\n",
       "75%        4.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of ratings in the yelp dataset\n",
    "rating_distribution = yelp_dataset.groupby(by=['rating']).size().reset_index(name=\"Count\").set_index('rating')\n",
    "rating_distribution.plot(kind=\"bar\", y='Count')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lowercased Name</th>\n",
       "      <th>Lowercased Address</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!hello tacos!</td>\n",
       "      <td>816 w randolph st</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 chop suey</td>\n",
       "      <td>7342 s stony island ave</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 liquors</td>\n",
       "      <td>1000 w belmont ave</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101 n wacker dr</td>\n",
       "      <td>101 n wacker dr</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1048 sky lounge - wrigley rooftop</td>\n",
       "      <td>1048 waveland ave</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Lowercased Name       Lowercased Address  rating\n",
       "0                      !hello tacos!        816 w randolph st     3.5\n",
       "1                        1 chop suey  7342 s stony island ave     2.5\n",
       "2                       1000 liquors       1000 w belmont ave     2.5\n",
       "3                    101 n wacker dr          101 n wacker dr     4.0\n",
       "4  1048 sky lounge - wrigley rooftop        1048 waveland ave     3.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the Yelp dataset to have the Price and rating for each restaurant \n",
    "yelp_dataset_grouped = yelp_dataset[['Lowercased Name', 'Lowercased Address', 'rating']].groupby(by=['Lowercased Name', 'Lowercased Address'])\\\n",
    "                                   .agg({'rating':'mean'}).reset_index()\n",
    "yelp_dataset_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the name and address columns in order to merge correctly\n",
    "features_dataframe['Lowercased Name'] = features_dataframe['DBA Name'].str.lower()\n",
    "features_dataframe['Lowercased Address'] = features_dataframe['Address'].str.lower()\n",
    "\n",
    "features_dataframe['Lowercased Name'] = features_dataframe['Lowercased Name'].astype(str).str.strip()\n",
    "features_dataframe['Lowercased Address'] = features_dataframe['Lowercased Address'].astype(str).str.strip()\n",
    "\n",
    "features_dataframe['Lowercased Name'] = [features_dataframe['Lowercased Name'][i].translate(str.maketrans('', '', string.punctuation))\\\n",
    "                                         .replace(\" \", \"\") for i in (range(len(features_dataframe)))]\n",
    "\n",
    "yelp_dataset_grouped['Lowercased Name'] = [yelp_dataset_grouped['Lowercased Name'][i].translate(str.maketrans('', '', string.punctuation))\\\n",
    "                                           .replace(\" \", \"\") for i in (range(len(yelp_dataset_grouped)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge features_dataframe with yelp_dataset_grouped in order to get the rating scores for each restaurant locations:\n",
    "features_df = features_dataframe.merge(yelp_dataset_grouped, \n",
    "                                       how='left', \n",
    "                                       left_on=['Lowercased Name', 'Lowercased Address'],\n",
    "                                       right_on=['Lowercased Name', 'Lowercased Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBA Name                                     0\n",
       "Address                                      0\n",
       "Community Area                               0\n",
       "Facility Type                                0\n",
       "Latitude                                     0\n",
       "Longitude                                    0\n",
       "Violation Counts                             0\n",
       "Critical Violations Count                    0\n",
       "Moderate Violations Count                    0\n",
       "Non-Critical Violations Count                0\n",
       "Successful Inspection Count                  0\n",
       "Failed Inspection Count                      0\n",
       "VomitDiarrheal Yes Counts                    0\n",
       "VomitDiarrheal No Counts                     0\n",
       "Allergen Yes Counts                          0\n",
       "Allergen No Counts                           0\n",
       "Total Inspections Result Counts              0\n",
       "Total VomitDiarrheal Flag Counts             0\n",
       "Total Allergen Flag Counts                   0\n",
       "Violation per Inspection                     0\n",
       "Critical Violation per Inspection            0\n",
       "Moderate Violation per Inspection            0\n",
       "Non-Critical Violation per Inspection        0\n",
       "Success Ratio of Inspections                 0\n",
       "Failure Ratio of Inspections                 0\n",
       "Yes Ratio of VomitDiarrheal                  0\n",
       "No Ratio of VomitDiarrheal                   0\n",
       "Yes Ratio of Allergen                        0\n",
       "No Ratio of Allergen                         0\n",
       "Critical Violations Ratio                    0\n",
       "Moderate Violations Ratio                    0\n",
       "Non-Critical Violations Ratio                0\n",
       "Chain flag                                   0\n",
       "Lowercased Name                              0\n",
       "Lowercased Address                           0\n",
       "rating                                   12788\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are still NaN values in the dataset\n",
    "features_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 12788 NaN values for the rating column in the dataset. Let's see if we can find more information about them. In particular, we can try to find other branches for the establishments with missing ratings and use these ratings to calculate an average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature dataframe subset\n",
    "features_df_subset = features_df[['Lowercased Name', 'Lowercased Address', 'rating']]\\\n",
    "                                     .groupby(by=['Lowercased Name', 'Lowercased Address'])\\\n",
    "                                     .agg({'rating':'mean'})\\\n",
    "                                     .reset_index()\\\n",
    "                                     .sort_values(by=['Lowercased Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lowercased Name</th>\n",
       "      <th>product</th>\n",
       "      <th>Count</th>\n",
       "      <th>weighted_average_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10pinbowlinglounge</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11degreesnorth</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14parish</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1914club</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1stchopsuey</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>zenwinespirits</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>ziggyssidedoorpubdeli</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>zocalo</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>zokusushi</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>zoup</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3316 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Lowercased Name  product  Count  weighted_average_rating\n",
       "0        10pinbowlinglounge      3.5      1                     3.50\n",
       "1            11degreesnorth      4.5      1                     4.50\n",
       "2                  14parish      4.5      1                     4.50\n",
       "3                  1914club      4.5      1                     4.50\n",
       "4               1stchopsuey      3.5      1                     3.50\n",
       "...                     ...      ...    ...                      ...\n",
       "3311         zenwinespirits      4.5      1                     4.50\n",
       "3312  ziggyssidedoorpubdeli      5.0      1                     5.00\n",
       "3313                 zocalo      3.5      1                     3.50\n",
       "3314              zokusushi      3.5      1                     3.50\n",
       "3315                   zoup      7.5      2                     3.75\n",
       "\n",
       "[3316 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create s subset of the dataframe where there is no NaN value in the rating column\n",
    "features_df_no_nan_ratings = features_df_subset[(pd.notna(features_df_subset['rating']))].drop_duplicates().reset_index().drop(['index'],axis=1)\n",
    "# Group by Lowercase and rating to be able to calculate the weighted average ratings\n",
    "grouped_by_name = features_df_no_nan_ratings.groupby(by=['Lowercased Name', 'rating']).size().reset_index(name=\"Count\")\n",
    "# Create a new column that is simply a product of rating and the number of restaurant names\n",
    "grouped_by_name['product'] = grouped_by_name['rating']*grouped_by_name['Count']\n",
    "grouped_by_name = grouped_by_name.groupby(by=['Lowercased Name'])\\\n",
    "                                        .agg({'product': 'sum',\n",
    "                                              'Count':'sum'}).reset_index()\n",
    "# Create a new column which shows the weighted average ratings of each restaurants\n",
    "grouped_by_name['weighted_average_rating'] = round(grouped_by_name['product']/grouped_by_name['Count'],2)\n",
    "grouped_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature dataframes where the rating column is NaN and not NaN\n",
    "features_df_nans = features_df[features_df['rating'].isnull()].reset_index().drop('index', axis=1)\n",
    "features_df_filled = features_df[~pd.isnull(features_df['rating'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the dataset that we have the weighted average rating information in it\n",
    "merged_features_df_nans = features_df_nans.merge(grouped_by_name[['Lowercased Name', 'weighted_average_rating']], \n",
    "                                                 how='left', \n",
    "                                                 left_on=['Lowercased Name'],\n",
    "                                                 right_on=['Lowercased Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBA Name                                     0\n",
       "Address                                      0\n",
       "Community Area                               0\n",
       "Facility Type                                0\n",
       "Latitude                                     0\n",
       "Longitude                                    0\n",
       "Violation Counts                             0\n",
       "Critical Violations Count                    0\n",
       "Moderate Violations Count                    0\n",
       "Non-Critical Violations Count                0\n",
       "Successful Inspection Count                  0\n",
       "Failed Inspection Count                      0\n",
       "VomitDiarrheal Yes Counts                    0\n",
       "VomitDiarrheal No Counts                     0\n",
       "Allergen Yes Counts                          0\n",
       "Allergen No Counts                           0\n",
       "Total Inspections Result Counts              0\n",
       "Total VomitDiarrheal Flag Counts             0\n",
       "Total Allergen Flag Counts                   0\n",
       "Violation per Inspection                     0\n",
       "Critical Violation per Inspection            0\n",
       "Moderate Violation per Inspection            0\n",
       "Non-Critical Violation per Inspection        0\n",
       "Success Ratio of Inspections                 0\n",
       "Failure Ratio of Inspections                 0\n",
       "Yes Ratio of VomitDiarrheal                  0\n",
       "No Ratio of VomitDiarrheal                   0\n",
       "Yes Ratio of Allergen                        0\n",
       "No Ratio of Allergen                         0\n",
       "Critical Violations Ratio                    0\n",
       "Moderate Violations Ratio                    0\n",
       "Non-Critical Violations Ratio                0\n",
       "Chain flag                                   0\n",
       "Lowercased Name                              0\n",
       "Lowercased Address                           0\n",
       "rating                                   12788\n",
       "weighted_average_rating                  11615\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are still NaN values for the rating information\n",
    "merged_features_df_nans.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precentage of the NaN ratings in the yelp dataset over the feature dataset after recovering from the weighted average rating scores is: 69.19%.\n"
     ]
    }
   ],
   "source": [
    "print('The precentage of the NaN ratings in the yelp dataset over the feature dataset after recovering from the weighted average rating scores is: {}%.'.format(round(100*len(merged_features_df_nans[pd.isna(merged_features_df_nans['weighted_average_rating'])])/len(features_df),2)))\n",
    "                                                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Yelp dataset does not give us ratings for all the establishments that we have in our main dataset. Roughly 69% of our establishments have no rating information. However, we will keep the rating information from Yelp dataset for safety score calculation, because it could be interesting to see the score results with including Yelp user ratings. Let's finalize to gather all the information into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for beign able to do merge\n",
    "features_df_filled['weighted_average_rating'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \n",
    "features_df = pd.concat([features_df_filled, merged_features_df_nans]).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 for ratings\n",
    "features_df['weighted_average_rating'].fillna(0, inplace=True)\n",
    "features_df['rating'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Yelp Rating'\n",
    "features_df['Yelp Rating'] = [(max(features_df['rating'][i], features_df['weighted_average_rating'][i])/5) for i in range(len(features_df))] # We divide by 5 to normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_score = features_df[['DBA Name','Address','Community Area', 'Facility Type', 'Latitude', 'Longitude',\n",
    "                                  'Violation per Inspection', 'Critical Violation per Inspection', \n",
    "                                  'Moderate Violation per Inspection', 'Non-Critical Violation per Inspection',  \n",
    "                                  'Critical Violations Ratio', 'Yes Ratio of VomitDiarrheal', 'Yes Ratio of Allergen',\n",
    "                                  'Yelp Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final features to pickle\n",
    "features_for_score.to_pickle('pickles/features_for_score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
